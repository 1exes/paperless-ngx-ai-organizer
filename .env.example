# =============================================================================
# Paperless-NGX Organizer - Konfiguration
# =============================================================================
# Kopiere diese Datei nach .env und passe die Werte an.
# Alle Werte haben sinnvolle Defaults (rechts vom = Zeichen).

# --- Paperless-NGX Server ---
PAPERLESS_URL=https://your-paperless-instance.example.com
PAPERLESS_TOKEN=dein-api-token-hier
OWNER_ID=1
# Name des Dokumentenbesitzers (fuer Learning-Profil Defaults)
ORGANIZER_OWNER_NAME=Document Owner

# --- LLM Server (Ollama/LM Studio/OpenAI-kompatibel) ---
# URL zum LLM-Endpunkt. Ollama: http://host:11434/api/chat
LLM_URL=http://localhost:11434/api/chat
# Modell-Name (leer = Server-Default). Empfohlen: qwen2.5:14b
LLM_MODEL=qwen2.5:14b
# API-Key (nur fuer OpenAI-kompatible APIs, leer fuer Ollama)
LLM_API_KEY=
# Optionaler System-Prompt (leer = keiner)
LLM_SYSTEM_PROMPT=
# Wie lange Ollama das Modell im RAM behaelt (z.B. 30m, 1h, 0=sofort entladen)
LLM_KEEP_ALIVE=30m
# Timeouts in Sekunden
LLM_CONNECT_TIMEOUT=6
LLM_TIMEOUT=120
LLM_COMPACT_TIMEOUT=50
# Anzahl Retries bei LLM-Fehlern
LLM_RETRY_COUNT=1
# Max Token-Limits fuer LLM-Antworten
LLM_MAX_TOKENS=320
LLM_COMPACT_MAX_TOKENS=220
# Temperatur (0.0=deterministisch, 1.0=kreativ). Fuer Klassifikation: 0.1-0.3
LLM_TEMPERATURE=0.2
# Bei niedriger Konfidenz zweiten LLM-Aufruf zur Verifikation starten
LLM_VERIFY_ON_LOW_CONFIDENCE=0
# Fallback-Modell bei wiederholten LLM-Fehlern (leer=deaktiviert)
LLM_FALLBACK_MODEL=
# Anzahl Fehler bevor auf Fallback-Modell gewechselt wird
LLM_FALLBACK_AFTER_ERRORS=3

# --- Organizer Laufzeit ---
# Testmodus: 1=nur anzeigen, 0=aendern
DEFAULT_DRY_RUN=0
# Anzahl paralleler Worker (1=sequenziell)
AGENT_WORKERS=1
# Max Tags pro Dokument
MAX_TAGS_PER_DOC=5
# Tag-Taxonomie erzwingen (nur Tags aus taxonomy_tags.json erlauben)
ENFORCE_TAG_TAXONOMY=1
# Neue Tags erlauben die nicht in der Taxonomie sind
ALLOW_NEW_TAGS=0
# Neue Korrespondenten erlauben
ALLOW_NEW_CORRESPONDENTS=0
# Ungenutzte Korrespondenten loeschen
DELETE_UNUSED_CORRESPONDENTS=0
# Korrespondenten-Merge: Mindestanzahl Dokumente in Gruppe
CORRESPONDENT_MERGE_MIN_GROUP_DOCS=2
# Korrespondenten-Merge: Mindest-Namensaehnlichkeit (0.0-1.0)
CORRESPONDENT_MERGE_MIN_NAME_SIMILARITY=0.96

# --- Learning-System ---
# Anzahl Few-Shot-Beispiele im LLM-Prompt (mehr=genauer, langsamer)
LEARNING_EXAMPLE_LIMIT=5
# Maximale Anzahl gespeicherter Beispiele
LEARNING_MAX_EXAMPLES=2000
# Learning-Priors aktivieren (nutzt bestaetigte Beispiele fuer Vorhersagen)
ENABLE_LEARNING_PRIORS=1
# Max Anzahl Prior-Hinweise pro Dokument
LEARNING_PRIOR_MAX_HINTS=2
# Mindestanzahl Beispiele fuer einen Korrespondenten bevor Priors greifen
LEARNING_PRIOR_MIN_SAMPLES=2
# Mindest-Uebereinstimmungsrate fuer Prior-Vorschlaege (0.0-1.0)
LEARNING_PRIOR_MIN_RATIO=0.70
# Tag-Vorschlaege aus Priors aktivieren (max 2 Tags)
LEARNING_PRIOR_ENABLE_TAG_SUGGESTION=1
# Regelbasiert: Mindestanzahl Beispiele fuer LLM-Bypass
RULE_BASED_MIN_SAMPLES=10
# Regelbasiert: Mindest-Konsistenzrate fuer LLM-Bypass
RULE_BASED_MIN_RATIO=0.80

# --- Taxonomie & Tags ---
# Taxonomie-Tags automatisch erstellen wenn sie fehlen
AUTO_CREATE_TAXONOMY_TAGS=1
# Ungenutzte Taxonomie-Tags behalten
KEEP_UNUSED_TAXONOMY_TAGS=1
# Max Gesamtanzahl Tags im System
MAX_TOTAL_TAGS=100

# --- Speicherpfade ---
# Neue Speicherpfade erlauben
ALLOW_NEW_STORAGE_PATHS=0

# --- Review-System ---
# Name des Review-Tags
REVIEW_TAG_NAME=Manuell-Pruefen
# Review-Tag automatisch setzen bei Problemen
AUTO_APPLY_REVIEW_TAG=1
# Auch bei mittlerer Konfidenz zur Review schicken
REVIEW_ON_MEDIUM_CONFIDENCE=0

# --- Web-Hinweise (Firmen-Erkennung via Websuche) ---
# Echte Websuche fuer unbekannte Entitaeten aktivieren (benoetigt: pip install ddgs)
ENABLE_WEB_HINTS=0
# Max Anzahl Web-Suchen pro Dokument
WEB_HINT_MAX_ENTITIES=2

# --- Fehler-Handling ---
# Dokumente mit kuerzlichen LLM-Fehlern ueberspringen (Minuten)
SKIP_RECENT_LLM_ERRORS_MINUTES=240
# Schwelle: ab wie vielen Fehlern ueberspringen
SKIP_RECENT_LLM_ERRORS_THRESHOLD=1

# --- Live-Watch Modus ---
LIVE_WATCH_INTERVAL_SEC=45
LIVE_WATCH_CONTEXT_REFRESH_CYCLES=5
LIVE_WATCH_COMPACT_FIRST=1

# --- Kontext-Erkennung ---
MAX_CONTEXT_EMPLOYER_HINTS=20
WORK_CORR_EMPLOYER_MIN_DOCS=8

# --- Autopilot Modus ---
AUTOPILOT_INTERVAL_SEC=45
AUTOPILOT_CONTEXT_REFRESH_CYCLES=5
AUTOPILOT_START_WITH_AUTO_ORGANIZE=1
AUTOPILOT_RECHECK_ALL_ON_START=0
AUTOPILOT_CLEANUP_EVERY_CYCLES=10
AUTOPILOT_DUPLICATE_SCAN_EVERY_CYCLES=0
AUTOPILOT_REVIEW_RESOLVE_EVERY_CYCLES=15
AUTOPILOT_MAX_NEW_DOCS_PER_CYCLE=25

# --- Ruhestunden (Verarbeitung pausieren, 0=deaktiviert) ---
# Beispiel: 23:00 - 06:00 Uhr keine Verarbeitung
QUIET_HOURS_START=0
QUIET_HOURS_END=0

# --- Logging ---
# Log-Level: DEBUG, INFO, WARNING, ERROR (Default: INFO)
LOG_LEVEL=INFO

# --- Sonstiges ---
RECHECK_ALL_DOCS_IN_AUTO=0
AUTO_CLEANUP_AFTER_ORGANIZE=1
USE_ARCHIVE_SERIAL_NUMBER=0
CORRESPONDENT_MATCH_THRESHOLD=0.90
NON_TAXONOMY_DELETE_THRESHOLD=5
DELETE_USED_TAGS=0
